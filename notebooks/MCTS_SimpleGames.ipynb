{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCTS\n",
    "for simple 2-person games\n",
    "Algorithm based on https://www.youtube.com/watch?v=UXW2yZndl7U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game Definitions\n",
    "\n",
    "#### Connect 2\n",
    "Game based on http://joshvarty.github.io/AlphaZero/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Connect2:\n",
    "    def __init__(self, board=None, played=None, terminated=None, reward=None):\n",
    "        # board and reward is not \"perspective corrected\"\n",
    "        # player - O: 1, X: -1\n",
    "\n",
    "        # self.board_:\n",
    "        # [ 0 1 2 3 ]\n",
    "        if board is None:\n",
    "            self.raw_board = [0 for i in range(4)]\n",
    "        else:\n",
    "            self.raw_board = list(board)\n",
    "\n",
    "        # game starts with a change of player, so set to opponent\n",
    "        if played is None:\n",
    "            self.played = -1\n",
    "        else:\n",
    "            self.played = played\n",
    "\n",
    "        self.terminated = False if terminated is None else terminated\n",
    "\n",
    "        if reward is None:\n",
    "            self.raw_reward = 0\n",
    "        else:\n",
    "            self.raw_reward = reward\n",
    "\n",
    "    def state(self):\n",
    "        return {\n",
    "            \"board\": self.raw_board,\n",
    "            \"played\": self.played,\n",
    "            \"terminated\": self.terminated,\n",
    "            \"reward\": self.raw_reward\n",
    "        }\n",
    "\n",
    "    def valid_actions(self):\n",
    "        # non-zero locations can be valid actions\n",
    "        ret = []\n",
    "        if self.terminated:\n",
    "            return ret\n",
    "        for idx, val in enumerate(self.raw_board):\n",
    "            if val == 0:\n",
    "                ret.append(idx)\n",
    "        return ret\n",
    "\n",
    "    def board(self, perspective=None):\n",
    "        # perspective\n",
    "        # - None: raw_board\n",
    "        # - played: \"played\" player's perspective\n",
    "        # - to_play: \"to_play\" player's perspective\n",
    "        # - -1, 1: selected player's perspective\n",
    "        if perspective is None:\n",
    "            return self.raw_board\n",
    "        elif perspective == \"played\":\n",
    "            return [k * self.played for k in self.raw_board]\n",
    "        elif perspective == \"to_play\":\n",
    "            return [k * -self.played for k in self.raw_board]\n",
    "        return [k * perspective for k in self.raw_board]\n",
    "\n",
    "    def reward(self, perspective=None):\n",
    "        if perspective is None:\n",
    "            return self.raw_reward\n",
    "        elif perspective == \"played\":\n",
    "            return self.raw_reward * self.played\n",
    "        elif perspective == \"to_play\":\n",
    "            return self.raw_reward * -self.played\n",
    "        return self.raw_reward * perspective\n",
    "        \n",
    "    def _eval_win(self, player):\n",
    "        # check if player has won - enumerate all win positions\n",
    "        win_positions = np.array([\n",
    "            [0, 1], [1, 2], [2, 3]\n",
    "        ])\n",
    "        has_win = np.any(\n",
    "            np.all((\n",
    "                np.array(self.raw_board)[win_positions.ravel()] == player\n",
    "            ).reshape(*win_positions.shape), axis=1)\n",
    "        )\n",
    "        return has_win\n",
    "    \n",
    "    def step(self, action, debug=False):\n",
    "        if self.raw_board[action] == 0:\n",
    "            self.raw_board[action] = -self.played\n",
    "        else:\n",
    "            # invalid action\n",
    "            if debug:\n",
    "                print(\"step: invalid action\")\n",
    "            if self.terminated is False:\n",
    "                # automatic win for other player\n",
    "                self.raw_reward = self.played\n",
    "            self.terminated = True\n",
    "\n",
    "        # player played\n",
    "        self.played = -self.played\n",
    "\n",
    "        if self._eval_win(self.played):\n",
    "            if debug:\n",
    "                print(\"step: eval_win\")\n",
    "            if self.terminated is False:\n",
    "                self.raw_reward = self.played\n",
    "            self.terminated = True\n",
    "\n",
    "        if len(self.valid_actions()) == 0:\n",
    "            if debug:\n",
    "                print(\"step: no more valid actions\")\n",
    "            # tie if not already terminated?\n",
    "            self.terminated = True\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def render(self):\n",
    "        print(\"[\", end=\" \")\n",
    "        for j in range(4):\n",
    "            val = self.raw_board[j]\n",
    "            s = \" \"\n",
    "            if val == 1:\n",
    "                s = \"O\"\n",
    "            elif val == -1:\n",
    "                s = \"X\"\n",
    "            print(s, end=\" \")\n",
    "        print(\"]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TicTacToe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToe:\n",
    "    def __init__(self, board=None, played=None, terminated=None, reward=None):\n",
    "        # board and reward is not \"perspective corrected\"\n",
    "        # player - O: 1, X: -1\n",
    "\n",
    "        # self.board_:\n",
    "        # [ 0 1 2\n",
    "        #   3 4 5\n",
    "        #   6 7 8 ]\n",
    "        if board is None:\n",
    "            self.raw_board = [0 for i in range(9)]\n",
    "        else:\n",
    "            self.raw_board = list(board)\n",
    "\n",
    "        # game starts with a change of player, so set to opponent\n",
    "        if played is None:\n",
    "            self.played = -1\n",
    "        else:\n",
    "            self.played = played\n",
    "\n",
    "        self.terminated = False if terminated is None else terminated\n",
    "\n",
    "        if reward is None:\n",
    "            self.raw_reward = 0\n",
    "        else:\n",
    "            self.raw_reward = reward\n",
    "\n",
    "    def state(self):\n",
    "        return {\n",
    "            \"board\": self.raw_board,\n",
    "            \"played\": self.played,\n",
    "            \"terminated\": self.terminated,\n",
    "            \"reward\": self.raw_reward\n",
    "        }\n",
    "\n",
    "    def valid_actions(self):\n",
    "        # non-zero locations can be valid actions\n",
    "        ret = []\n",
    "        if self.terminated:\n",
    "            return ret\n",
    "        for idx, val in enumerate(self.raw_board):\n",
    "            if val == 0:\n",
    "                ret.append(idx)\n",
    "        return ret\n",
    "\n",
    "    def board(self, perspective=None):\n",
    "        # perspective\n",
    "        # - None: raw_board\n",
    "        # - played: \"played\" player's perspective\n",
    "        # - to_play: \"to_play\" player's perspective\n",
    "        # - -1, 1: selected player's perspective\n",
    "        if perspective is None:\n",
    "            return self.raw_board\n",
    "        elif perspective == \"played\":\n",
    "            return [k * self.played for k in self.raw_board]\n",
    "        elif perspective == \"to_play\":\n",
    "            return [k * -self.played for k in self.raw_board]\n",
    "        return [k * perspective for k in self.raw_board]\n",
    "\n",
    "    def reward(self, perspective=None):\n",
    "        if perspective is None:\n",
    "            return self.raw_reward\n",
    "        elif perspective == \"played\":\n",
    "            return self.raw_reward * self.played\n",
    "        elif perspective == \"to_play\":\n",
    "            return self.raw_reward * -self.played\n",
    "        return self.raw_reward * perspective\n",
    "        \n",
    "    def _eval_win(self, player):\n",
    "        # check if player has won - enumerate all win positions\n",
    "        win_positions = np.array([\n",
    "            [0, 1, 2], [3, 4, 5], [6, 7, 8],\n",
    "            [0, 3, 6], [1, 4, 7], [2, 5, 8],\n",
    "            [0, 4, 8], [2, 4, 6],\n",
    "        ])\n",
    "        has_win = np.any(\n",
    "            np.all((\n",
    "                np.array(self.raw_board)[win_positions.ravel()] == player\n",
    "            ).reshape(*win_positions.shape), axis=1)\n",
    "        )\n",
    "        return has_win\n",
    "    \n",
    "    def step(self, action, debug=False):\n",
    "        if self.raw_board[action] == 0:\n",
    "            self.raw_board[action] = -self.played\n",
    "        else:\n",
    "            # invalid action\n",
    "            if debug:\n",
    "                print(\"step: invalid action\")\n",
    "            if self.terminated is False:\n",
    "                # automatic win for other player\n",
    "                self.raw_reward = self.played\n",
    "            self.terminated = True\n",
    "\n",
    "        # player played\n",
    "        self.played = -self.played\n",
    "\n",
    "        if self._eval_win(self.played):\n",
    "            if debug:\n",
    "                print(\"step: eval_win\")\n",
    "            if self.terminated is False:\n",
    "                self.raw_reward = self.played\n",
    "            self.terminated = True\n",
    "\n",
    "        if len(self.valid_actions()) == 0:\n",
    "            if debug:\n",
    "                print(\"step: no more valid actions\")\n",
    "            # tie if not already terminated?\n",
    "            self.terminated = True\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def render(self):\n",
    "        for j in range(3):\n",
    "            print(\"[\", end=\" \")\n",
    "            for i in range(3):\n",
    "                val = self.raw_board[j * 3 + i]\n",
    "                s = \" \"\n",
    "                if val == 1:\n",
    "                    s = \"O\"\n",
    "                elif val == -1:\n",
    "                    s = \"X\"\n",
    "                print(s, end=\" \")\n",
    "            print(\"]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_win_positions_connect4():\n",
    "    win_positions = []\n",
    "    # vertical check\n",
    "    for col in range(7):\n",
    "        c = np.array([[0, 7, 14, 21], [7, 14, 21, 28], [14, 21, 28, 35]]) + col\n",
    "        c = c.tolist()\n",
    "        win_positions.extend(c)\n",
    "    # horizontal check\n",
    "    for row in range(6):\n",
    "        c = np.array([[0, 1, 2, 3], [1, 2, 3, 4], [2, 3, 4, 5], [3, 4, 5, 6]]) + 7*row\n",
    "        c = c.tolist()\n",
    "        win_positions.extend(c)\n",
    "    # diagonal (top-left to bottom-right check)\n",
    "    start_pts = [0, 1, 2, 3, 7, 8, 9, 10, 14, 15, 16, 17]\n",
    "    c = []\n",
    "    for pt in start_pts:\n",
    "        ci = [(pt + 8*i) for i in range(4)]\n",
    "        c.append(ci)\n",
    "    win_positions.extend(c)\n",
    "    # diagonal (top-right to bottom-left check)\n",
    "    start_pts = [3, 4, 5, 6, 10, 11, 12, 13, 17, 18, 19, 20]\n",
    "    c = []\n",
    "    for pt in start_pts:\n",
    "        ci = [(pt + 6*i) for i in range(4)]\n",
    "        c.append(ci)\n",
    "    win_positions.extend(c)\n",
    "    win_positions = np.array(win_positions)\n",
    "    return win_positions\n",
    "\n",
    "def valid_action_connect4(board):\n",
    "    valid_actions = []\n",
    "    for i in range(7):\n",
    "        row_idxs = list(reversed([(i + j * 7) for j in range(6)]))\n",
    "        for idx in row_idxs:\n",
    "            if board[idx] == 0:\n",
    "                valid_actions.append(idx)\n",
    "                break\n",
    "    return valid_actions\n",
    "\n",
    "class Connect4:\n",
    "    def __init__(self, board=None, played=None, terminated=None, reward=None):\n",
    "        # board and reward is not \"perspective corrected\"\n",
    "        # player - O: 1, X: -1\n",
    "\n",
    "        # self.raw_board:\n",
    "        # [  0  1  2  3  4  5  6\n",
    "        #    7  8  9 10 11 12 13\n",
    "        #   14 15 16 17 18 19 20\n",
    "        #   21 22 23 24 25 26 27\n",
    "        #   28 29 30 31 32 33 34\n",
    "        #   35 36 37 38 39 40 41 ]\n",
    "        if board is None:\n",
    "            self.raw_board = [0 for i in range(42)]\n",
    "        else:\n",
    "            self.raw_board = list(board)\n",
    "\n",
    "        # game starts with a change of player, so set to opponent\n",
    "        if played is None:\n",
    "            self.played = -1\n",
    "        else:\n",
    "            self.played = played\n",
    "\n",
    "        self.terminated = False if terminated is None else terminated\n",
    "\n",
    "        if reward is None:\n",
    "            self.raw_reward = 0\n",
    "        else:\n",
    "            self.raw_reward = reward\n",
    "\n",
    "    def state(self):\n",
    "        return {\n",
    "            \"board\": self.raw_board,\n",
    "            \"played\": self.played,\n",
    "            \"terminated\": self.terminated,\n",
    "            \"reward\": self.raw_reward\n",
    "        }\n",
    "\n",
    "    def valid_actions(self):\n",
    "        ret = []\n",
    "        if self.terminated:\n",
    "            return ret\n",
    "        ret = valid_action_connect4(self.raw_board)\n",
    "        return ret\n",
    "\n",
    "    def board(self, perspective=None):\n",
    "        # perspective\n",
    "        # - None: raw_board\n",
    "        # - played: \"played\" player's perspective\n",
    "        # - to_play: \"to_play\" player's perspective\n",
    "        # - -1, 1: selected player's perspective\n",
    "        if perspective is None:\n",
    "            return self.raw_board\n",
    "        elif perspective == \"played\":\n",
    "            return [k * self.played for k in self.raw_board]\n",
    "        elif perspective == \"to_play\":\n",
    "            return [k * -self.played for k in self.raw_board]\n",
    "        return [k * perspective for k in self.raw_board]\n",
    "\n",
    "    def reward(self, perspective=None):\n",
    "        if perspective is None:\n",
    "            return self.raw_reward\n",
    "        elif perspective == \"played\":\n",
    "            return self.raw_reward * self.played\n",
    "        elif perspective == \"to_play\":\n",
    "            return self.raw_reward * -self.played\n",
    "        return self.raw_reward * perspective\n",
    "        \n",
    "    def _eval_win(self, player):\n",
    "        # check if player has won - enumerate all win positions\n",
    "        win_positions = get_win_positions_connect4()\n",
    "        has_win = np.any(\n",
    "            np.all((\n",
    "                np.array(self.raw_board)[win_positions.ravel()] == player\n",
    "            ).reshape(*win_positions.shape), axis=1)\n",
    "        )\n",
    "        return has_win\n",
    "    \n",
    "    def step(self, action, debug=False):\n",
    "        if self.terminated is False and action in self.valid_actions():\n",
    "        #if self.raw_board[action] == 0:\n",
    "            self.raw_board[action] = -self.played\n",
    "        else:\n",
    "            # invalid action\n",
    "            if debug:\n",
    "                print(\"step: invalid action\")\n",
    "            if self.terminated is False:\n",
    "                # automatic win for other player\n",
    "                self.raw_reward = self.played\n",
    "            self.terminated = True\n",
    "\n",
    "        # player played\n",
    "        self.played = -self.played\n",
    "\n",
    "        if self._eval_win(self.played):\n",
    "            if debug:\n",
    "                print(\"step: eval_win\")\n",
    "            if self.terminated is False:\n",
    "                self.raw_reward = self.played\n",
    "            self.terminated = True\n",
    "\n",
    "        if len(self.valid_actions()) == 0:\n",
    "            if debug:\n",
    "                print(\"step: no more valid actions\")\n",
    "            # tie if not already terminated?\n",
    "            self.terminated = True\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def render(self):\n",
    "        for j in range(6):\n",
    "            print(\"[\", end=\" \")\n",
    "            for i in range(7):\n",
    "                val = self.raw_board[j * 7 + i]\n",
    "                s = \" \"\n",
    "                if val == 1:\n",
    "                    s = \"O\"\n",
    "                elif val == -1:\n",
    "                    s = \"X\"\n",
    "                print(s, end=\" \")\n",
    "            print(\"|\", end=\" \")\n",
    "            for i in range(7):\n",
    "                idx = j * 7 + i\n",
    "                print(\"%2d\" % idx, end=\" \")\n",
    "            print(\"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#game_class = Connect2\n",
    "#game_class = TicTacToe\n",
    "game_class = Connect4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_game_status(g):\n",
    "    g.render()\n",
    "    print(\"%2d\" % g.played, \"b:     \", g.board(perspective=\"played\"), end=\"\")\n",
    "    print(\" | T:\", g.terminated, \"| R:\", g.reward(perspective=\"played\"), \"[\" + str(g.reward()) + \"]\")\n",
    "    print(\"%2d\" % -g.played, \"next_a:\", g.valid_actions())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = game_class()\n",
    "render_game_status(g)\n",
    "#for action in [3, 2, 0, 1]: # connect2\n",
    "#for action in [3, 2, 0, 6, 4, 5, 7, 8]: # tictactoe\n",
    "for action in [38, 37, 31, 30, 24, 23, 17]: # connect4\n",
    "    g.step(action)\n",
    "    render_game_status(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_rollout(g, n_steps=None, debug=False):\n",
    "    current_player = g.played * -1\n",
    "    if debug:\n",
    "        print(\"current player:\", current_player)\n",
    "    step = 0\n",
    "    while g.terminated is False:\n",
    "        valid_actions = g.valid_actions()\n",
    "        action_idx = np.random.choice(len(valid_actions))\n",
    "        action = valid_actions[action_idx]\n",
    "        g.step(action)\n",
    "        if debug:\n",
    "            print(\"player\", \"%2d\" % g.played, \"plays  \")\n",
    "            g.render()\n",
    "        step += 1\n",
    "        if n_steps is not None:\n",
    "            if step >= n_steps:\n",
    "                break\n",
    "    if debug:\n",
    "        print(\"final board state\")\n",
    "        g.render()\n",
    "        print(\"final reward (as current player):\",\n",
    "              g.reward(perspective=current_player))\n",
    "    return g.reward(perspective=current_player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = game_class()\n",
    "random_rollout(g, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCTS Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, prior, game_state, game_class=None, node_id=None):\n",
    "        self.prior = prior # not used for pure MCTS\n",
    "        self.game_state = game_state\n",
    "        self.game_class = game_class\n",
    "        self.node_id = node_id\n",
    "\n",
    "        self.children = {}\n",
    "        self.visit_count = 0\n",
    "        self.value_sum = 0\n",
    "\n",
    "    def value(self):\n",
    "        return self.value_sum / self.visit_count\n",
    "\n",
    "    def is_leaf_node(self):\n",
    "        return len(self.children) == 0\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"%s: prior: %5.2f, n_child: %d, n_visit: %d, value_sum: %d\" %\\\n",
    "            (str(self.node_id), self.prior, len(self.children), self.visit_count, self.value_sum)\n",
    "    \n",
    "    def restore_game(self):\n",
    "        if self.game_class:\n",
    "            return self.game_class(**self.game_state)\n",
    "        return None\n",
    "\n",
    "    def print_tree(self, depth=None):\n",
    "        # currently max depth = 4\n",
    "        if depth is None:\n",
    "            depth = 999\n",
    "        print(self)\n",
    "        for i1 in self.children.keys():\n",
    "            n1 = self.children[i1]\n",
    "            print(\" \", n1)\n",
    "            if depth >= 2:\n",
    "                for i2 in n1.children.keys():\n",
    "                    n2 = n1.children[i2]\n",
    "                    print(\"   \", n2)\n",
    "                    if depth >= 3:\n",
    "                        for i3 in n2.children.keys():\n",
    "                            n3 = n2.children[i3]\n",
    "                            print(\"     \", n3)\n",
    "                            if depth >= 4:\n",
    "                                for i4 in n3.children.keys():\n",
    "                                    n4 = n3.children[i4]\n",
    "                                    print(\"       \", n4)\n",
    "\n",
    "def rollout(node, search_path, debug=False):\n",
    "    if debug:\n",
    "        print(\"rollout from\", node.node_id)\n",
    "    g = node.restore_game()\n",
    "    if debug:\n",
    "        g.render()\n",
    "    current_player = g.played * -1\n",
    "    reward = random_rollout(g, debug=False)\n",
    "    if debug:\n",
    "        print(\"playing as\", current_player, \"reward:\", reward)\n",
    "        g.render()\n",
    "\n",
    "    mod_reward = reward\n",
    "    for n in reversed(search_path):\n",
    "        n.value_sum += mod_reward\n",
    "        n.visit_count += 1\n",
    "        mod_reward *= -1\n",
    "\n",
    "def ucb1(parent, child):\n",
    "    if child.visit_count == 0:\n",
    "        return np.inf\n",
    "    return (-child.value_sum / child.visit_count) + 2 * np.sqrt(np.log(parent.visit_count) / child.visit_count)\n",
    "    \"\"\" \n",
    "    # Definition from http://joshvarty.github.io/AlphaZero/\n",
    "    prior_score = child.prior * np.sqrt(parent.visit_count) / (child.visit_count + 1)\n",
    "    if child.visit_count > 0:\n",
    "        # The value of the child is from the perspective of the opposing player\n",
    "        value_score = -child.value()\n",
    "    else:\n",
    "        value_score = 0\n",
    "\n",
    "    return value_score + prior_score\n",
    "    \"\"\"\n",
    "\n",
    "def expand_node(node):\n",
    "    game_class = node.game_class\n",
    "    valid_actions = node.restore_game().valid_actions()\n",
    "    for action in valid_actions:\n",
    "        g = node.restore_game().step(action)\n",
    "        node.children[action] = Node(\n",
    "            1/len(valid_actions),\n",
    "            g.state(),\n",
    "            game_class,\n",
    "            node.node_id + \"-\" + str(action)\n",
    "        )\n",
    "    return valid_actions\n",
    "\n",
    "def run_mcts(node, num_simulations=5, debug=False):\n",
    "    game_class = node.game_class\n",
    "    for i in range(num_simulations):\n",
    "        current = node\n",
    "        search_path = [current]\n",
    "        if debug:\n",
    "            print()\n",
    "            print(\"simulation:\", i)\n",
    "        while not current.is_leaf_node():\n",
    "            #print(\"not_leaf_node\")\n",
    "            ucb1_max_value = None\n",
    "            ucb1_action = None\n",
    "            for action, child_node in current.children.items():\n",
    "                if ucb1_max_value is None:\n",
    "                    ucb1_max_value = ucb1(current, child_node)\n",
    "                    ucb1_action = action\n",
    "                else:\n",
    "                    ucb1_value = ucb1(current, child_node)\n",
    "                    if ucb1_max_value < ucb1_value:\n",
    "                        ucb1_max_value = ucb1_value\n",
    "                        ucb1_action = action\n",
    "            current = current.children[ucb1_action]\n",
    "            search_path.append(current)\n",
    "        if debug:\n",
    "            print(\"initial:\")\n",
    "            node.print_tree()\n",
    "\n",
    "        #print(\"is_leaf_node\")\n",
    "        if current.visit_count == 0:\n",
    "            #print(\"first rollout\")\n",
    "            rollout(current, search_path, debug=debug)\n",
    "            if debug:\n",
    "                node.print_tree()\n",
    "        else:\n",
    "            #print(\"expand and rollout\")\n",
    "            valid_actions = expand_node(current)\n",
    "\n",
    "            if len(valid_actions) == 0:\n",
    "                g = current.restore_game()\n",
    "                reward = g.reward(perspective=\"to_play\")\n",
    "                for n in reversed(search_path):\n",
    "                    n.value_sum += reward\n",
    "                    n.visit_count += 1\n",
    "                    reward *= -1\n",
    "            else:\n",
    "                first_action = valid_actions[0]\n",
    "                current = current.children[first_action]\n",
    "                search_path.append(current)\n",
    "\n",
    "                rollout(current, search_path, debug=debug)\n",
    "            if debug:\n",
    "                node.print_tree()\n",
    "    return node\n",
    "\n",
    "def get_visit_counts(node):\n",
    "    db = []\n",
    "    visit_counts = [0 for i in range(len(g.raw_board))]\n",
    "    for n in node.children:\n",
    "        db.append([n, node.children[n].visit_count])\n",
    "        visit_counts[n] = node.children[n].visit_count\n",
    "    if len(db) == 0:\n",
    "        return None, visit_counts\n",
    "    return sorted(db, key=lambda x: x[1], reverse=True)[0][0], visit_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Manual Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = game_class()\n",
    "node = Node(1, g.state(), game_class, node_id=\"root\")\n",
    "valid_actions = expand_node(node)\n",
    "#run_mcts(node, num_simulations=100, debug=False) # connect2\n",
    "#run_mcts(node, num_simulations=1000, debug=False) # tictactoe\n",
    "run_mcts(node, num_simulations=2000, debug=False) # connect4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node.print_tree(depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in g.valid_actions():\n",
    "    print(i, ucb1(node, node.children[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self Play Episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_self_play(game_class, num_simulations=100, run_status=True, debug=False):\n",
    "    action_sequence = []\n",
    "    stats = []\n",
    "    while True:\n",
    "        if run_status:\n",
    "            print(\".\", end=\"\")\n",
    "        g = game_class()\n",
    "        for action in action_sequence:\n",
    "            g.step(action)\n",
    "        node = Node(1, g.state(), game_class, node_id=\"root\")\n",
    "        valid_actions = expand_node(node)\n",
    "        run_mcts(node, num_simulations=num_simulations, debug=debug)\n",
    "        next_action, visit_counts = get_visit_counts(node)\n",
    "        if g.terminated is True or next_action is None:\n",
    "            for idx, (to_play, board, visit_prob, _) in enumerate(stats):\n",
    "                reward = g.reward(perspective=to_play)\n",
    "                stats[idx][-1] = reward\n",
    "            break\n",
    "        to_play = -g.played\n",
    "        board = g.board(perspective=to_play)\n",
    "        visit_prob = visit_counts / np.sum(visit_counts)\n",
    "        stats.append([to_play, board, visit_prob, 0])\n",
    "        action_sequence.append(next_action)\n",
    "    if run_status:\n",
    "        print()\n",
    "    return action_sequence, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#action_sequence, stats = run_self_play(game_class, 100) # connect2\n",
    "#action_sequence, stats = run_self_play(game_class, 1000) # tictactoe\n",
    "action_sequence, stats = run_self_play(game_class, 2000) # connect4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(action_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = game_class()\n",
    "for action in action_sequence:\n",
    "    print(\"play\", action)\n",
    "    g.step(action)\n",
    "    render_game_status(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive Play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_sequence = []\n",
    "while True:\n",
    "    g = game_class()\n",
    "    for action in action_sequence:\n",
    "        g.step(action)\n",
    "    g.render()\n",
    "    print()\n",
    "    action = input()\n",
    "    action = int(action)\n",
    "    action_sequence.append(action)\n",
    "    \n",
    "    g = game_class()\n",
    "    for action in action_sequence:\n",
    "        g.step(action)\n",
    "    g.render()\n",
    "    print()\n",
    "    node = Node(1, g.state(), game_class, node_id=\"root\")\n",
    "    valid_actions = expand_node(node)\n",
    "    run_mcts(node, num_simulations=2000, debug=False)\n",
    "    next_action, _ = get_visit_counts(node)\n",
    "    if next_action is None:\n",
    "        break\n",
    "    action_sequence.append(next_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
